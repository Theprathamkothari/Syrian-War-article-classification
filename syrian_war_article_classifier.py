# -*- coding: utf-8 -*-
"""Syrian War Article Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DzXD-ptFx9f11yPPzrcHA56qaEHsV2Nm
"""

import pandas as pd

# Load the dataset with a specified encoding
df = pd.read_csv("/content/FA-KES-Dataset.csv", encoding='ISO-8859-1')  # or 'latin1'

# Display the first few rows to confirm successful loading
df.head()

# Check for missing values
print(df.isnull().sum())

# Drop any irrelevant columns if necessary
df = df.drop(columns=['column_name'], errors='ignore')

import seaborn as sns
import matplotlib.pyplot as plt

# Plot class distribution
sns.countplot(data=df, x='labels')
plt.title("Distribution of Fake vs Real News")
plt.show()

df['word_count'] = df['article_title'].apply(lambda x: len(str(x).split()))
plt.figure(figsize=(10, 5))
sns.barplot(x='labels', y='word_count', data=df, estimator='mean', palette='viridis')
plt.title("Average Word Count by News Class")
plt.xlabel("News Class (0 = Fake, 1 = Real)")
plt.ylabel("Average Word Count")
plt.show()

# Additional Visualization 2: Top Words by Class (Real vs. Fake)
from collections import Counter

# Fake News Word Frequencies
fake_words = ' '.join(df[df['labels'] == 0]['article_title'])
fake_word_counts = Counter(fake_words.split()).most_common(10)

# Real News Word Frequencies
real_words = ' '.join(df[df['labels'] == 1]['article_title'])
real_word_counts = Counter(real_words.split()).most_common(10)

# Plot as bar chart
fig, axs = plt.subplots(1, 2, figsize=(15, 6))
sns.barplot(x=[word for word, count in fake_word_counts], y=[count for word, count in fake_word_counts], ax=axs[0], palette='magma')
sns.barplot(x=[word for word, count in real_word_counts], y=[count for word, count in real_word_counts], ax=axs[1], palette='cool')
axs[0].set_title("Top Words in Fake News")
axs[1].set_title("Top Words in Real News")
axs[0].tick_params(labelrotation=45)
axs[1].tick_params(labelrotation=45)
plt.tight_layout()
plt.show()

# Additional Visualization 3: Distribution of News Length by Class
plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='word_count', hue='labels', kde=True, palette='Set1', bins=30)
plt.title("Distribution of News Length by Class")
plt.xlabel("Word Count")
plt.ylabel("Frequency")
plt.legend(title='Class', labels=['Fake', 'Real'])
plt.show()

from wordcloud import WordCloud, STOPWORDS

# Word cloud for fake news
fake_news = df[df['labels'] == 0]['article_title']
wordcloud = WordCloud(stopwords=STOPWORDS, background_color='black').generate(" ".join(fake_news))
plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Fake News Word Cloud")
plt.show()

# Word cloud for real news
real_news = df[df['labels'] == 1]['article_title']
wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white').generate(" ".join(real_news))
plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Real News Word Cloud")
plt.show()

import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# Function to clean the text
def clean_text(text):
    text = re.sub(r'\W', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.lower()

# Apply cleaning
df['cleaned_text'] = df['article_title'].apply(clean_text)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['labels'], test_size=0.2, random_state=42)

# Vectorize the text
vectorizer = TfidfVectorizer(max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Train logistic regression
log_reg = LogisticRegression()
log_reg.fit(X_train_vec, y_train)

# Predict and evaluate
y_pred = log_reg.predict(X_test_vec)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt

# Build the neural network
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_vec.shape[1],)),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_vec, y_train, epochs=5, batch_size=32, validation_data=(X_test_vec, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test_vec, y_test)
print(f"Neural Network Accuracy: {accuracy * 100:.2f}%")

# Predictions
y_pred_prob = model.predict(X_test_vec).ravel()  # Predicted probabilities
y_pred = (y_pred_prob > 0.5).astype("int32")     # Convert probabilities to binary predictions

# Metrics
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_pred_prob)

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")
print(f"AUC: {auc:.2f}")

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, label=f"Neural Network (AUC = {auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label="Random Guessing")
plt.title("Receiver Operating Characteristic (ROC) Curve (Neural Network)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

def predict_news(text):
    text = clean_text(text)
    vector = vectorizer.transform([text])
    prediction = model.predict(vector)
    return "Real News" if prediction >= 0.5 else "Fake News"

# Accept input from the user
news = input("Enter the news text to predict: ")

# Predict and display the result
result = predict_news(news)
print(f"The prediction is: {result}")